# -*- coding: utf-8 -*-
"""Contrast+Retinex.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wlOnj8I4C5ivnhgXB52N3yyJbjB0vHqM
"""

import cv2
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# !pip install roboflow

# from roboflow import Roboflow
# rf = Roboflow(api_key="wbs3ef01W1OQTdLhbY9o")
# project = rf.workspace("auv-hackathon").project("underwater-object-detection-s8xhb")
# dataset = project.version(1).download("coco")

# #This is the code to download the dataset

# """# New Section"""

# #im_list=[]
# #def im_read(n):
#  # for i in range(n):
#   #  print('Upload File:')
#    # upl_file=files.upload()
#     #for filename, content in upl_file.items():
#      # nparr = np.frombuffer(content, np.uint8)
#       #img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
#       #if img is not None:
#        #     im_list.append(img)
#       #else:
#        #     print(f"Error reading image: {filename}")

# #m=int(input('Enter no. of images'))
# #im_read(m)

# train_path = '/content/Underwater-object-detection-1/train/'
# test_path='/content/Underwater-object-detection-1/test/'
# valid_path='/content/Underwater-object-detection-1/valid/'
# train_cont = os.listdir('/content/Underwater-object-detection-1/train/')
# test_cont=os.listdir('/content/Underwater-object-detection-1/test/')
# valid_cont=os.listdir('/content/Underwater-object-detection-1/valid/')
# train_str=[]
# test_str=[]
# valid_str=[]

# for item in train_cont:
#   if item != "_annotations.coco.json":
#     train_str.append(train_path+item)

# for item in test_cont:
#   if item != "_annotations.coco.json":
#     test_str.append(test_path+item)

# for item in valid_cont:
#   if item != "_annotations.coco.json":
#     valid_str.append(valid_path+item)

# train_images=[]
# for item in train_str:
#    img = (cv2.imread(item,cv2.IMREAD_COLOR)).astype(np.uint8)
#    img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#    train_images.append(img)
#    plt.imshow(img)
#    plt.show()

# test_images=[]
# for item in test_str:
#    img = (cv2.imread(item,cv2.IMREAD_COLOR)).astype(np.uint8)
#    img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#    test_images.append(img)
#    plt.imshow(img)
#    plt.show()

# valid_images=[]
# for item in valid_str:
#    img = (cv2.imread(item,cv2.IMREAD_COLOR)).astype(np.uint8)
#    img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#    valid_images.append(img)
#    plt.imshow(img)
#    plt.show()

#Unsharp masking
 #Note that the first image has more contrast but the 2nd is sharper (as demonstrated by lab cvt later)
#blurred = cv2.GaussianBlur(gr_image, (15,15), 0)
#unsharp_gry1 = cv2.addWeighted(gr_image, 3.5, blurred, -1.5, 0)
#unsharp_gry2 = cv2.addWeighted(gr_image, 3.5, blurred, -3.35, 0)

#unsharp_image1 = cv2.cvtColor(unsharp_gry1, cv2.COLOR_GRAY2BGR)
#unsharp_image2=cv2.cvtColor(unsharp_gry2, cv2.COLOR_GRAY2BGR)
#cv2_imshow(unsharp_image1)
#cv2_imshow(unsharp_image2)
#cv2.imwrite('usm.jpg', unsharp_image)
#files.download('usm.jpg')

#BGR TO LAB CVT on the Unsharp Darker Image
#lab_image = cv2.cvtColor(unsharp_image2, cv2.COLOR_BGR2LAB)

# Separate the L (lightness) channel from LAB image
#lt, agr, bby = cv2.split(lab_image)

#l_eq = cv2.equalizeHist(lt)
#Lenh_image = cv2.merge([l_eq, agr, bby])

#cv2_imshow(image)
#cv2_imshow(Lenh_image)
#cv2.imwrite('Lenh_image.jpg',Lenh_image)
#files.download('Lenh_image.jpg')

#WORKING CONTRAST METHOD BEGINS AFTER THIS

#Color Channel Enhancement
def col_enh(img):
   b, g, r = cv2.split(img)
   enh_g = cv2.addWeighted(g, 1.09, np.zeros_like(g), 0, 0)
   enh_b = cv2.addWeighted(b, 0.93, np.zeros_like(b), 0, 0)
   enh_r = cv2.addWeighted(r, 3, np.zeros_like(r), 0, 0)

   enh_image = cv2.merge([enh_b,enh_g,enh_r])
   return(enh_image)

   #Beginning with Retinex
def ret(enh_img):
   im_float = enh_img.astype(np.float32) / 255.0

   log_img = np.log1p(im_float)
   retinex = im_float - cv2.GaussianBlur(log_img, (0, 0), 50)

   # Scale the values back to the range [0, 255]
   retinex = np.clip(retinex * 255.0, 0, 255).astype(np.uint8)
   return(retinex)


# new_train=[]

# for img in train_images:
#    enh_img=col_enh(img)
#    new_train.append(ret(enh_img))

# new_test=[]

# for img in test_images:
#    enh_img=col_enh(img)
#    new_test.append(ret(enh_img))

# new_valid=[]

# for img in valid_images:
#    enh_img=col_enh(img)
#    new_valid.append(ret(enh_img))

# for img in new_test:
#     plt.imshow(img)
#     plt.show()

# for img in new_train:
#    rghs(img)
#    plt.imshow(img)

#from PIL import Image, ImageEnhance
#img=Image.fromarray(ret[1])
#enhancer = ImageEnhance.Brightness(img)
#factor=1.5
#img_brightened = np.array(enhancer.enhance(factor))
